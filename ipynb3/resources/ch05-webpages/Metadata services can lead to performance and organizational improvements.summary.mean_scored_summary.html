b'<html>\n    <head>\n        <title>Metadata services can lead to performance and organizational improvements Summary</title>\n        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>\n    </head>\n    <body><p>Subscribe to the O\'Reilly Data Show Podcast<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/> to explore the opportunities and techniques driving big data and data science: <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Stitcher<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>, <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>TuneIn<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>, <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>iTunes<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>, <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>SoundCloud<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>, <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>RSS<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Strata+Hadoop World<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>: \xc2\xa0Joe Hellerstein, p<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>rofessor of Computer Science at UC Berkeley<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/> and <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>co-founder/CSO of Trifacta<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>. We talked about his past and current academic research (which spans <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>HCI<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Data wrangling and preparation<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Coordination and consistency in distributed systems<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms\xe2\x80\x94<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>locking<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>, <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Paxos<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\xe2\x80\x94\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>CALM theorem: consistency as logical monotonicity<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Vendor-neutral metadata services<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. <strong>It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>[caption id="attachment_81743" align="aligncenter" width="600"]<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/> <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. <strong>It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Use cases for metadata.</strong> Source: Joe Hellerstein, used with permission.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>[/caption]<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Joe Hellerstein will speak about <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>metadata services<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/> and <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>data wrangling<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/> at <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Strata + Hadoop World in San Jose this March<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Related resources:<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>We need open and vendor-neutral metadata services<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Lessons from next-generation data wrangling tools<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Data wrangling gets a fresh look<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>Image by <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>xOneca on Wikimedia Commons<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>.<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n<p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/> <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/> <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/> <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/> <p><strong><a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220?intcmp=il-data-na-na-na_20150826_radar_data_show_podcast_post_top_subscribe_cta">Subscribe to the O\'Reilly Data Show Podcast</a></strong> to explore the opportunities and techniques driving big data and data science: <a href="//www.stitcher.com/podcast/oreilly-media-2/the-oreilly-data-show-podcast?refid=stpr\xe2\x80\x9d">Stitcher</a>, <a href="http://tunein.com/radio/OReilly-Data-Show-p670015/">TuneIn</a>, <a href="https://itunes.apple.com/us/podcast/oreilly-data-show/id944929220">iTunes</a>, <a href="https://soundcloud.com/oreilly-radar/sets/the-oreilly-data-show-podcast">SoundCloud</a>, <a href="http://feeds.podtrac.com/IOJSwQcdEBcg">RSS</a>.</p>\n<p><a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png" rel="attachment wp-att-81739"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/350px-Hand_made_dense_labyrinth.jpg" alt="350px-Hand_made_dense_labyrinth" width="350" height="251" class="alignright size-full wp-image-81739" /></a>\n<p>In this episode of the O\'Reilly Data Show, I spoke with one of the most popular speakers at <a href="http://www.strataconf.com">Strata+Hadoop World</a>: \xc2\xa0Joe Hellerstein, p<a href="http://db.cs.berkeley.edu/jmh/">rofessor of Computer Science at UC Berkeley</a> and <a href="https://www.trifacta.com/about-us/leadership/">co-founder/CSO of Trifacta</a>. We talked about his past and current academic research (which spans <a href="https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction">HCI</a>, databases, and systems), data wrangling, large-scale distributed systems, and his recent work on metadata services.</p>\n<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/246374456&amp;auto_play=false&amp;hide_related=false&amp;show_artwork=true" height="166" width="100%" frameborder="no"></iframe></p>\n<h2>Data wrangling and preparation</h2>\n<blockquote><p>The most interactive tasks that people do with data are essentially data wrangling. You\'re changing the form of the data, you\'re changing the content of the data, and at the same time you\'re trying to evaluate the quality of the data and see if you\'re making it the way you want it. \xe2\x80\xa6 It\'s really actually the most immersive interaction that people do with data and it\'s very interesting.</p>\n<p><!--more--></p>\n<p>\xe2\x80\xa6 Actually, there\'s a long tradition of research in the database community on data cleaning and some on data transformation languages, some of that work from my group, and certainly lots of work from many, many others. You will see papers about that. It tends to be more algorithmic and automated traditionally. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Most of that work was, \'I\'ve invented an algorithm.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> It can do entity resolution ten percent better than the previous algorithm, and let me show you how it works.\' I think a distinguishing factor in the work that we\'ve been doing is that we\'ve reached out to researchers in human-computer interaction, people like Jeff Heer, who focus on things like visualization, things like interaction models, and we asked, \'Well, it\'s nice to have an algorithm, but how will the person using this algorithm actually iterate over the data?\' That raises different and equally interesting, or maybe more interesting in my opinion, technical challenges.</p>\n</blockquote>\n<h2>Coordination and consistency in distributed systems</h2>\n<blockquote><p>What\'s the fundamental bottleneck in scale and in performance? \xe2\x80\xa6 \xc2\xa0When you read the systems and the big data papers, it\'s all about coordination. It\'s the cost of a machine in California waiting for an answer from a machine in London to just get permission to do what it wants to do. Coordination algorithms&mdash;<a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">locking</a>, <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>&mdash;\xe2\x80\xa6 are very expensive. The big question we all had was: How can you get correct semantics on your data and correct execution in your programs if you don\'t coordinate, if the systems don\'t bother checking in with each other to make sure everything\'s okay? </p>\n<p>\xe2\x80\xa6 Achieving consistency without coordination is the big goal. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NoSQL is very much about saying, \'Forget about consistency.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Let\'s just avoid coordination.\' What the goal in the research community has been over the bunch of years is to say, \'Well, that\'s not a good trade off. Can we get both? Can we get consistency without coordination?\' The answer turns out to be lots of times, yes, and there\'s been lots of mechanism and fundamentals both in this space that are ... going to be really powerful tools for computing going forward.</p>\n<p>\xe2\x80\xa6 What I\'d say instead is that you can achieve strong consistency in a very broad set of tasks. One of the key results in this is the <a href="http://bloom-lang.net/calm/">CALM theorem: consistency as logical monotonicity</a>, that comes out of my group. The CALM theorem shows that any polynomial time algorithm can be implemented without coordination and achieve a consistent outcome, which means that basically anything you want to compute in a reasonable amount of time over large amounts of data doesn\'t really require coordination. Now, that\'s a theory result. <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Mapping it to practice is going to be the work of many years and lots of clever ideas, but fundamentally I think it\'s quite broadly applicable.</p>\n</blockquote>\n<h2>Vendor-neutral metadata services</h2>\n<p>As Hellerstein discussed, the use cases for metadata are varied and evolving.</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> Some key uses of metadata and metadata stores include interpreting data, tracking data usage by multiple users, and surfacing patterns and associations among many data sets.</p>\n<p>[caption id="attachment_81743" align="aligncenter" width="600"]<a href="Joe Hellerstein, used with permission" rel="attachment wp-att-81743"><img src="http://s.radar.oreilly.com/wp-files/2/2016/02/600px-metadata2-joe-nyc-2015.jpg" alt="Use cases for metadata" width="600" height="301" class="size-full wp-image-81743" /></a> <em>Use cases for metadata. Source: Joe Hellerstein, used with permission.</em>[/caption]</p>\n<blockquote><p>Let me talk about the kinds of things I think a metadata store in the big data space needs to do in its fullness. One of them obviously is it needs to be a place where you put your data inventory. That\'s the standard stuff. What data do I have? How\'s it named? How\'s it typed? How\'s it structured? How\'s it accessed? What kinds of things are in it? Most of these systems at minimum need to do that. That\'s fine. A second layer that I think is critical moving forward ... is data usage. Every time an analyst does a thing to a data set and generates some output, we should be tracking that because there is gold in those hills. Every time someone puts in time and skill into analyzing data and using it, that\'s generating metadata that could be useful to your organization.</p>\n<p>\xe2\x80\xa6 I think we want to use metadata for organizational improvements. Who knows about this data? Expert sourcing. Who knows about data that references customer X? Maybe somebody did a study of sales to customer X, and you can find that out. Who knows about this data set? Then there\'s things like, if you\'re working with this data set, you might be interested in this other data set. There\'s a kind of recommender system version of this relative to data. There are lots of things you can do beyond make the system go faster if you know how people are working with the data. It\'s really a graph of people and data and algorithms interacting. It evolves over time and you want to mine that graph for patterns.</p>\n</blockquote>\n<p><em>Joe Hellerstein will speak about <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47237?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">metadata services</a> and <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca/public/schedule/detail/47405?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_session_link">data wrangling</a> at <a href="http://conferences.oreilly.com/strata/hadoop-big-data-ca?intcmp=il-data-confreg-lp-stca16_20160209_radar_joe_hellerstein_data_show_post_conference_link">Strata + Hadoop World in San Jose this March</a>.</em></p>\n<p><strong>Related resources:</strong></p>\n<ul>\n<li><a href="https://www.oreilly.com/ideas/we-need-open-and-vendor-neutral-metadata-services">We need open and vendor-neutral metadata services</a></li>\n<li><a href="http://radar.oreilly.com/2015/01/lessons-from-next-generation-data-wrangling-tools.html">Lessons from next-generation data wrangling tools</a></li>\n<li><a href="http://radar.oreilly.com/2013/11/data-wrangling-gets-a-fresh-look.html">Data wrangling gets a fresh look</a></li>\n</ul>\n<p><em>Image by <a href="https://commons.wikimedia.org/wiki/File:Hand_made_dense_labyrinth.png">xOneca on Wikimedia Commons</a>.</em></p>\n<div class="feedflare">\n<a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:V_sGLiPBpWU" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=yIl2AUoC8zA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?i=uXEnwAwAYo4:kIc8Z7X_C0g:JEwB19i1-c4" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=7Q72WNTAKBA" border="0"></img></a> <a href="http://feeds.feedburner.com/~ff/oreilly/radar/atom?a=uXEnwAwAYo4:kIc8Z7X_C0g:qj6IDK7rITs"><img src="http://feeds.feedburner.com/~ff/oreilly/radar/atom?d=qj6IDK7rITs" border="0"></img></a>\n</div><img src="http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/uXEnwAwAYo4" height="1" width="1" alt=""/>\n</p></body>\n</html>'